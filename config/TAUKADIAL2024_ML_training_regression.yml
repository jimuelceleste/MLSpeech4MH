name: "TAUKADIAL2024 ML Training - Regression"
description: "Experiment protocol to compare different pipelines with Nested Subject-Wise CV."

training_config:
  technique: "nested_cross_validation" # "flat_cross_validation"
  parameters:
    task: "regression"
    metadata__label_column: "regression_label"
    outer_fold__technique: "subject_wise" # "record_wise"
    outer_fold__n_splits: 5
    outer_fold__random_state: 42
    outer_fold__shuffle: True 
    inner_fold__technique: "subject_wise" # "record_wise"
    inner_fold__n_splits: 5
    inner_fold__random_state: 42 
    inner_fold__shuffle: True
    optimization__technique: "grid_search" # "bayes_search"
    optimization__scoring: "neg_root_mean_squared_error"
    evaluation__metrics: [
      "root_mean_squared_error",
      "mean_absolute_error",
      "r2_score", 
      "mean_squared_error",
      "mean_absolute_percentage_error"
    ]

pipeline_config: 
  - unique_id: "random_forest_regressor"
    steps: 
      feature_scaler: "standard_scaler"
      feature_selector: "select_k_best"
      model: "random_forest_regressor"
    parameters:
      feature_scaler__with_mean: [True]
      feature_scaler__with_std: [True]
      # feature_selector__k: [22, 44, 66, 88] # {25, 50, 75, 100}% of 88 eGeMAPS features
      # feature_selector__k: [
      #   1593, # ~25% of 6374 ComParE 2016 features
      #   3187, # ~50%
      #   4780, # ~75%
      #   6373  # 100%
      # ]
      # feature_selector__k: [
      #   36,  # ~25% of 141 LFTK handcrafted features 
      #   71,  # ~50%
      #   106, # ~75%
      #   141  # 100%
      # ]
      # feature_selector__k: [
      #   16, # ~25% of 61 Lexico-semantic Features
      #   31, # ~50%
      #   46, # ~75%
      #   61  # 100%
      # ]
      # feature_selector__k: [
      #   18, # ~25% of 69 Syntax Features
      #   35, # ~50%
      #   52, # ~75%
      #   69  # 100%
      # ]
      feature_selector__k: [ 
        58,   # 25% of 229 eGeMAPS + LFTK Features
        115,  # 50%
        172,  # 75%
        229   # 100%
      ]
      model__n_estimators: [100, 300, 500, 700]
      model__max_features: [5, 15, 25, 35, 45, 55]
      model__min_samples_leaf: [1, 2, 3, 4]

  - unique_id: "svm_regressor"
    steps: 
      feature_scaler: "standard_scaler"
      feature_selector: "select_k_best"
      model: "support_vector_regressor"
    parameters:
      feature_scaler__with_mean: [True]
      feature_scaler__with_std: [True]
      # feature_selector__k: [22, 44, 66, 88] # {25, 50, 75, 100}% of 88 eGeMAPS features
      # feature_selector__k: [
      #   1593, # 25% of 6374 ComParE 2016 features
      #   3187, # 50%
      #   4780, # 75%
      #   6373  # 100%
      # ]
      # feature_selector__k: [
      #   36,  # ~25% of 141 LFTK handcrafted features 
      #   71,  # ~50%
      #   106, # ~75%
      #   141  # 100%
      # ]
      # feature_selector__k: [
      #   16, # ~25% of 61 Lexico-semantic Features
      #   31, # ~50%
      #   46, # ~75%
      #   61  # 100%
      # ]
      # feature_selector__k: [
      #   18, # ~25% of 69 Syntax Features
      #   35, # ~50%
      #   52, # ~75%
      #   69  # 100%
      # ]
      feature_selector__k: [ 
        58,   # 25% of 229 eGeMAPS + LFTK Features
        115,  # 50%
        172,  # 75%
        229   # 100%
      ]
      model__C: [0.1, 1, 10, 100, 1000]
      model__kernel: ['linear', 'poly', 'rbf']
      model__gamma: [1, 0.1, 0.01, 0.001, "scale"]
      model__max_iter: [50, 100, 150]

  - unique_id: "linear_regression"
    steps: 
      feature_scaler: "standard_scaler"
      feature_selector: "select_k_best"
      model: "linear_regressor"
    parameters:
      feature_scaler__with_mean: [True]
      feature_scaler__with_std: [True]
      # feature_selector__k: [22, 44, 66, 88] # {25, 50, 75, 100}% of 88 eGeMAPS features
      # feature_selector__k: [
      #   1593, # 25% of 6374 ComParE 2016 features
      #   3187, # 50%
      #   4780, # 75%
      #   6373  # 100%
      # ]
      # feature_selector__k: [
      #   36,  # ~25% of 141 LFTK handcrafted features 
      #   71,  # ~50%
      #   106, # ~75%
      #   141  # 100%
      # ]
      # feature_selector__k: [
      #   16, # ~25% of 61 Lexico-semantic Features
      #   31, # ~50%
      #   46, # ~75%
      #   61  # 100%
      # ]
      # feature_selector__k: [
      #   18, # ~25% of 69 Syntax Features
      #   35, # ~50%
      #   52, # ~75%
      #   69  # 100%
      # ]
      feature_selector__k: [ 
        58,   # 25% of 229 eGeMAPS + LFTK Features
        115,  # 50%
        172,  # 75%
        229   # 100%
      ]

  - unique_id: "xgb_regression"
    steps: 
      feature_scaler: "standard_scaler"
      feature_selector: "select_k_best"
      model: "xgb_regressor"
    parameters:
      feature_scaler__with_mean: [True]
      feature_scaler__with_std: [True]
      # feature_selector__k: [22, 44, 66, 88] # {25, 50, 75, 100}% of 88 eGeMAPS features
      # feature_selector__k: [
      #   1593, # 25% of 6374 ComParE 2016 features
      #   3187, # 50%
      #   4780, # 75%
      #   6373  # 100%
      # ]
      # feature_selector__k: [
      #   36,  # ~25% of 141 LFTK handcrafted features 
      #   71,  # ~50%
      #   106, # ~75%
      #   141  # 100%
      # ]
      # feature_selector__k: [
      #   16, # ~25% of 61 Lexico-semantic Features
      #   31, # ~50%
      #   46, # ~75%
      #   61  # 100%
      # ]
      # feature_selector__k: [
      #   18, # ~25% of 69 Syntax Features
      #   35, # ~50%
      #   52, # ~75%
      #   69  # 100%
      # ]
      feature_selector__k: [ 
        58,   # 25% of 229 eGeMAPS + LFTK Features
        115,  # 50%
        172,  # 75%
        229   # 100%
      ]
      model__max_depth: [5, 6, 7, 8]
      model__learning_rate: [0.02, 0.05, 0.07, 0.1]
      model__n_estimators: [50, 100, 200, 500, 1000]

  - unique_id: "multilayer_perceptron_regressor"
    steps: 
      feature_scaler: "standard_scaler"
      # feature_selector: "select_k_best"
      model: "multilayer_perceptron_regressor"
    parameters:
      feature_scaler__with_mean: [True]
      feature_scaler__with_std: [True]
      # feature_selector__k: [22, 44, 66, 88]
      model__alpha: [0.0001]
      model__hidden_layer_sizes: [[55, 160, 160, 55]]
      model__learning_rate_init: [0.001]
      model__max_iter: [10000]

  - unique_id: "multilayer_perceptron_regressor-feature_selection"
    steps: 
      feature_scaler: "standard_scaler"
      feature_selector: "select_k_best"
      model: "multilayer_perceptron_regressor"
    parameters:
      feature_scaler__with_mean: [True]
      feature_scaler__with_std: [True]
      # feature_selector__k: [22, 44, 66, 88]
      # feature_selector__k: [
      #   36,  # ~25% of 141 LFTK handcrafted features 
      #   71,  # ~50%
      #   106, # ~75%
      #   141  # 100%
      # ]
      feature_selector__k: [ 
        58,   # 25% of 229 eGeMAPS + LFTK Features
        115,  # 50%
        172,  # 75%
        229   # 100%
      ]
      model__alpha: [0.0001]
      model__hidden_layer_sizes: [[55, 160, 160, 55]]
      model__learning_rate_init: [0.001]
      model__max_iter: [10000]

  - unique_id: "multilayer_perceptron_100_regressor-feature_selection"
    steps: 
      feature_scaler: "standard_scaler"
      feature_selector: "select_k_best"
      model: "multilayer_perceptron_regressor"
    parameters:
      feature_scaler__with_mean: [True]
      feature_scaler__with_std: [True]
      # feature_selector__k: [22, 44, 66, 88]
      # feature_selector__k: [
      #   36,  # ~25% of 141 LFTK handcrafted features 
      #   71,  # ~50%
      #   106, # ~75%
      #   141  # 100%
      # ]
      feature_selector__k: [ 
        58,   # 25% of 229 eGeMAPS + LFTK Features
        115,  # 50%
        172,  # 75%
        229   # 100%
      ]
      model__alpha: [0.0001]
      model__hidden_layer_sizes: [[100]]
      model__learning_rate_init: [0.001]
      model__max_iter: [10000]